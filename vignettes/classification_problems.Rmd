---
title: "{SLmetrics}: Classification"
subtitle: "{SLmetrics} x {lightgbm} in classification problems"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{{SLmetrics}: Classification}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment  = "#>",
  message  = FALSE
)
```

```{r setup}
# load libraries
library(SLmetrics)
```


In this vignette, we will demonstrate how to use [{SLmetrics}](https://github.com/serkor1/SLmetrics) with [{lightgbm}](https://github.com/microsoft/LightGBM) for classification problems. 

> **Prerequisite:** Familiarity with [{lightgbm}](https://github.com/microsoft/LightGBM)  and the general AI/ML-workflow is assumed.

We will use the [Shutte](https://archive.ics.uci.edu/dataset/148/statlog+shuttle) dataset, made available via [{mlbench}](https://cran.r-project.org/web/packages/mlbench/index.html), as an example throughout this vignette.

## Setup

In this section we setup the essential the workflow for using [{SLmetrics}](https://github.com/serkor1/SLmetrics) with [{lightgbm}](https://github.com/microsoft/LightGBM).

### The data

```{r data}
# 1) load data
# from {mlbench}
data("Shuttle", package = "mlbench")
```

<details>
<summary> Showcase: speed comparison </summary>

```{r}
# 1.1) define the features
# and outcomes
outcome  <- c("Class")
features <- setdiff(x = colnames(Shuttle), y = outcome)

# 2) split data in training
# and test

# 2.1) set seed for 
# for reproducibility
set.seed(1903)

# 2.2) exttract
# indices with a simple
# 80/10 split
index <- sample(1:nrow(Shuttle), size = 0.8 * nrow(Shuttle))

# 1.1) extract training
# data and construct
# as lgb.Dataset
train <- Shuttle[index,]
dtrain <- lightgbm::lgb.Dataset(
    data  = data.matrix(train[,features]),
    label = train$Class
)
# 1.2) extract test
# data
test <- Shuttle[-index,]


# 1.2.1) extract actual
# values and constuct
# as.factor for {SLmetrics}
# methods
actual <- as.factor(
    test$Class
)

# 1.2.2) construct as data.matrix
# for predict method
test <- data.matrix(
    test[,features]
)
```

</details>


### Setting up parameters
```{r parameters}
# 1) define parameters
# across the vignette
parameters <- list(
    objective     = "multiclass",
    num_leaves    = 4L,
    learning_rate = 0.5,
    num_class     = 8
)
```

### Evaluation function: F score

As the custom evaluation function we use the $F_{score}$ with $\beta = 2$ to emphasize that precision is more imporant than recall. The function is defined as,

$$
f_\beta = (1 + \beta^2) \cdot \frac{precision \cdot recall}{(\beta^2 \cdot precision) + recall}
$$

The `fbeta()`-function returns a vector of scores for each class. We want to maximize the micro-average.

```{r}
# 1) define the custom
# evaluation metric
evaluation_metric <- function(
    dtrain, 
    preds) {

        # 1) extract values
        actual    <- as.factor(dtrain)
        predicted <- lightgbm::get_field(preds, "label")
        value     <- fbeta(
            actual    = actual,
            predicted = predicted,
            beta      = 2,
            micro     = TRUE
        )

        # 2) construnct output
        # list
        list(
            name          = "fbeta",
            value         = value,
            higher_better = TRUE 
        )
    
}
```

## Training model

We train the the model using the `lgb.train()`-function,

```{r}
model <- lightgbm::lgb.train(
    params  = parameters,
    data    = dtrain,
    nrounds = 10L,
    eval    = evaluation_metric,
    verbose = -1
)
```

## Performance Evaluation

### Classification

We extract the predicted classes using the `predict()`-function,

```{r forecasts}
# 1) prediction
# from the model
predicted <- as.factor(
    predict(
        model,
        newdata = test,
        type = "class"
    )
)
```

```{r cmatrix}
# 1) construct confusion
# matrix
confusion_matrix <- cmatrix(
    actual = actual,
    predicted = predicted
)

# 2) visualize
plot(
    confusion_matrix
)

# 3) summarize
summary(
    confusion_matrix
)
```


### Response

We extract the response values using the `predict()`-function,

```{r response}
# 1) prediction
# from the model
response <- predict(
        model,
        newdata = test
    )

```

```{r ROC}
# 1) viasualize
# ROC
plot(
    ROC(
    actual,
    response = response
)
)
```