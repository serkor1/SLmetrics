% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R, R/S3_precision.R
\name{precision.factor}
\alias{precision.factor}
\alias{precision.cmatrix}
\alias{ppv.factor}
\alias{ppv.cmatrix}
\alias{precision}
\alias{ppv}
\title{Compute the \eqn{\text{precision}} or  \eqn{\text{positive predictive value}}}
\usage{
\method{precision}{factor}(actual, predicted, micro = NULL, na.rm = TRUE, ...)

\method{precision}{cmatrix}(x, micro = NULL, na.rm = TRUE, ...)

\method{ppv}{factor}(actual, predicted, micro = NULL, na.rm = TRUE, ...)

\method{ppv}{cmatrix}(x, micro = NULL, na.rm = TRUE, ...)

precision(...)

ppv(...)
}
\arguments{
\item{actual}{A <\link{factor}>-vector of \link{length} \eqn{n}, and \eqn{k} levels.}

\item{predicted}{A <\link{factor}>-vector of \link{length} \eqn{n}, and \eqn{k} levels.}

\item{micro}{A <\link{logical}>-value of \link{length} \eqn{1}. \link{NULL} by default. If \link{TRUE} it returns the
micro average across all \eqn{k} classes, if \link{FALSE} it returns the macro average. Otherwise class wise performance evaluation.}

\item{na.rm}{A <\link{logical}>-value of \link{length} \eqn{1}. \link{TRUE} by default. If \link{FALSE} \link{NA} values will be disregarded when \code{micro = FALSE}.}

\item{...}{Arguments passed into other methods.}

\item{x}{A confusion matrix created by \code{\link[=table]{table()}} or \code{\link[=cmatrix]{cmatrix()}}}
}
\value{
If \code{aggregate} is \link{FALSE} (the default), a named <\link{numeric}>-vector of \link{length} k

If \code{aggregate} is \link{TRUE}, a <\link{numeric}>-vector of \link{length} 1
}
\description{
The \code{\link[=precision]{precision()}}-function computes the \href{https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values}{precision}, also known as the positive predictive value (PPV), between
two vectors of predicted and observed \code{\link[=factor]{factor()}} values.

When \code{aggregate = TRUE}, the function returns the micro-average precision across all classes \eqn{k}.
By default, it returns the class-wise precision.
}
\details{
Consider a classification problem with three classes: \code{A}, \code{B}, and \code{C}. The actual vector of \code{\link[=factor]{factor()}} values is defined as follows:

\if{html}{\out{<div class="sourceCode r">}}\preformatted{## set seed
set.seed(1903)

## actual
factor(
  x = sample(x = 1:3, size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#>  [1] B A B B A C B C C A
#> Levels: A B C
}\if{html}{\out{</div>}}

Here, the values 1, 2, and 3 are mapped to \code{A}, \code{B}, and \code{C}, respectively. Now, suppose your model does not predict any \code{B}'s. The predicted vector of \code{\link[=factor]{factor()}} values would be defined as follows:

\if{html}{\out{<div class="sourceCode r">}}\preformatted{## set seed
set.seed(1903)

## predicted
factor(
  x = sample(x = c(1, 3), size = 10, replace = TRUE),
  levels = c(1, 2, 3),
  labels = c("A", "B", "C")
)
#>  [1] C A C C C C C C A C
#> Levels: A B C
}\if{html}{\out{</div>}}

In both cases, \eqn{k = 3}, determined indirectly by the \code{levels} argument.
}
\section{Calculation}{


The metric is calculated for each class \eqn{k} as follows,

\deqn{
  \frac{\#TP_k}{\#TP_k + \#FP_k}
}

Where \eqn{\#TP_k} and \eqn{\#FP_k} are the number of true positives and false positives, respectively, for each class \eqn{k}.

When \code{aggregate = TRUE}, the \code{micro}-average is calculated,

\deqn{
  \frac{\sum_{k=1}^k \#TP_k}{\sum_{k=1}^k \#TP_k + \sum_{k=1}^k \#FP_k}
}
}

\examples{
# 1) recode Iris
# to binary classification
# problem
iris$Species <- factor(
  x = as.numeric(
    iris$Species == "virginica"
  ),
  levels = c(1,0),
  labels = c("virginica", "others")
)

# 2) fit the logistic
# regression
model <- glm(
  formula = Species ~ Sepal.Length + Sepal.Width,
  data    = iris,
  family = binomial(
    link = "logit"
  )
)

# 3) generate predicted
# classes
predicted <- as.factor(
  ifelse(
    predict(model, type = "response") > 0.5,
    yes = "virginica",
    no  = "others"
  )
)

# 4) evaluate performance
# 4.1) by class
precision(
  actual    = iris$Species,
  predicted = predicted
)

# 4.2) macro-average
precision(
  actual    = iris$Species,
  predicted = predicted,
  micro     = FALSE
)

# 4.3) micro-average
precision(
  actual    = iris$Species,
  predicted = predicted,
  micro     = TRUE
)
}
\seealso{
Other classification: 
\code{\link{accuracy.factor}()},
\code{\link{baccuracy.factor}()},
\code{\link{cmatrix}()},
\code{\link{dor.factor}()},
\code{\link{fbeta.factor}()},
\code{\link{fdr}()},
\code{\link{fer}()},
\code{\link{fmi}()},
\code{\link{fpr.factor}()},
\code{\link{jaccard.factor}()},
\code{\link{kappa}()},
\code{\link{mcc.factor}()},
\code{\link{nlr.factor}()},
\code{\link{npv}()},
\code{\link{plr.factor}()},
\code{\link{recall.factor}()},
\code{\link{specificity.factor}()},
\code{\link{zerooneloss}()}
}
\concept{classification}
