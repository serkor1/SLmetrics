# Generated by using Rcpp::compileAttributes() -> do not edit by hand
# Generator token: 10BE3573-1514-4C36-9D1C-5A225CD40393

#' Compute the \eqn{\text{fowlkes}}-\eqn{\text{fallows}} \eqn{\text{index}}
#'
#' @description
#' The [fmi()]-function computes the [Fowlkes-Mallows Index](https://en.wikipedia.org/wiki/Fowlkes%E2%80%93Mallows_index) (FMI), a measure of the similarity between two sets of clusterings, between
#' two vectors of predicted and observed [factor()] values.
#'
#' @usage
#' # fowlkes-mallows index
#' fmi(
#'   actual,
#'   predicted
#' )
#'
#' @example man/examples/scr_fmi.R
#'
#' @inherit specificity
#'
#' @section Calculation:
#'
#' The metric is calculated for each class \eqn{k} as follows,
#'
#' \deqn{
#'   \sqrt{\frac{\#TP_k}{\#TP_k + \#FP_k} \times \frac{\#TP_k}{\#TP_k + \#FN_k}}
#' }
#'
#' Where \eqn{\#TP_k}, \eqn{\#FP_k}, and \eqn{\#FN_k} represent the number of true positives, false positives, and false negatives for each class \eqn{k}, respectively.
#'
#'
#' @returns
#' A <[numeric]> vector of [length] 1
#'
#' @family classification
#'
#' @export
fmi <- function(actual, predicted) {
    .Call(`_SLmetrics_fmi`, actual, predicted)
}

#' @rdname accuracy
#' @method accuracy factor
#'
#' @export
accuracy.factor <- function(actual, predicted, ...) {
    .Call(`_SLmetrics_accuracy`, actual, predicted)
}

#' @rdname accuracy
#' @method accuracy cmatrix
#'
#' @export
accuracy.cmatrix <- function(x, ...) {
    .Call(`_SLmetrics_accuracy_cmatrix`, x)
}

#' @rdname baccuracy
#' @method baccuracy factor
#'
#' @export
baccuracy.factor <- function(actual, predicted, adjust = FALSE, ...) {
    .Call(`_SLmetrics_baccuracy`, actual, predicted, adjust)
}

#' @rdname baccuracy
#' @method baccuracy cmatrix
#'
#' @export
baccuracy.cmatrix <- function(x, adjust = FALSE, ...) {
    .Call(`_SLmetrics_baccuracy_cmatrix`, x, adjust)
}

#' Confusion Matrix
#'
#' @description
#'
#' The [cmatrix()]-function uses cross-classifying factors to build
#' a confusion matrix of the counts at each combination of the [factor] levels.
#' Each row of the [matrix] represents the actual [factor] levels, while each
#' column represents the predicted [factor] levels.
#'
#' @usage
#' cmatrix(
#'   actual,
#'   predicted
#' )
#'
#' @param actual A <[factor]>-vector of [length] \eqn{n}, and \eqn{k} levels.
#' @param predicted A <[factor]>-vector of [length] \eqn{n}, and \eqn{k} levels.
#'
#' @example man/examples/scr_confusionmatrix.R
#' @family classification
#'
#' @inherit specificity details
#'
#' @section Dimensions:
#'
#' There is no robust defensive measure against misspecififying
#' the confusion matrix. If the arguments are correctly specified, the resulting
#' confusion matrix is on the form:
#'
#' |            | A (Predicted) | B (Predicted) |
#' | :----------|:-------------:| -------------:|
#' | A (Actual) | Value         | Value         |
#' | B (Actual) | Value         | Value         |
#'
#'
#' @returns
#'
#' A named \eqn{k} x \eqn{k} <[matrix]> of [class] <cmatrix>
#'
#' @export
cmatrix <- function(actual, predicted) {
    .Call(`_SLmetrics_cmatrix`, actual, predicted)
}

#' Compute the \eqn{\text{diagnostic}} \eqn{\text{odds}} \eqn{\text{ratio}}
#'
#' @description
#' The [dor()]-function computes the [Diagnostic Odds Ratio](https://en.wikipedia.org/wiki/Diagnostic_odds_ratio) (DOR), a single indicator of test performance, between
#' two vectors of predicted and observed [factor()] values.
#'
#' When `aggregate = TRUE`, the function returns the micro-average DOR across all classes \eqn{k}. By default, it returns the class-wise DOR.
#'
#' @usage
#' dor(
#'   actual,
#'   predicted,
#'   aggregate = FALSE
#' )
#'
#' @example man/examples/scr_diagnosticodssratio.R
#'
#' @inherit specificity
#'
#' @section Calculation:
#'
#' The metric is calculated for each class \eqn{k} as follows,
#'
#' \deqn{
#'   \text{DOR}_k = \frac{\text{PLR}_k}{\text{NLR}_k}
#' }
#'
#' Where \eqn{\text{PLR}_k} and \eqn{\text{NLR}_k} is the positive and negative likelihood ratio for class \eqn{k}, respectively. See [plr()] and [nlr()] for more details.
#'
#' When `aggregate = TRUE`, the `micro`-average is calculated as,
#'
#' \deqn{
#'   \overline{\text{DOR}} = \frac{\overline{\text{PLR}_k}}{\overline{\text{NLR}_k}}
#' }
#'
#' Where \eqn{\overline{\text{PLR}}} and \eqn{\overline{\text{NLR}}} is the micro-averaged is the positive and negative likelihood ratio, respectively.
#'
#' @family classification
#'
#' @export
dor <- function(actual, predicted, aggregate = FALSE) {
    .Call(`_SLmetrics_dor`, actual, predicted, aggregate)
}

#' @rdname fbeta
#' @method fbeta factor
#'
#' @export
fbeta.factor <- function(actual, predicted, beta = 1.0, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_fbeta`, actual, predicted, beta, micro, na_rm = na.rm)
}

#' @rdname fbeta
#' @method fbeta cmatrix
#'
#' @export
fbeta.cmatrix <- function(x, beta = 1.0, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_fbeta_cmatrix`, x, beta, micro, na_rm = na.rm)
}

#' Compute the \eqn{\text{false}} \eqn{\text{discovery}} \eqn{\text{rate}}
#'
#' @description
#' The [fdr()]-function computes the [false discovery rate](https://en.wikipedia.org/wiki/False_discovery_rate) (FDR), the proportion of false positives among the predicted positives, between
#' two vectors of predicted and observed [factor()] values.
#'
#' When `aggregate = TRUE`, the function returns the micro-average FDR across all classes \eqn{k}. By default, it returns the class-wise FDR.
#'
#' @example man/examples/scr_fdr.R
#'
#' @usage
#' # false discovery rate;
#' fdr(
#'   actual,
#'   predicted,
#'   aggregate = FALSE
#' )
#'
#'
#' @inherit specificity
#'
#' @section Calculation:
#'
#' The metric is calculated for each class \eqn{k} as follows,
#'
#' \deqn{
#'   \frac{\#FP_k}{\#TP_k+\#FP_k}
#' }
#'
#' Where \eqn{\#TP_k} and \eqn{\#FP_k} is the number of true psotives and false positives, respectively, for each class \eqn{k}.
#'
#' When `aggregate = TRUE` the `micro`-average is calculated,
#'
#' \deqn{
#'  \frac{\sum_{k=1}^k \#FP_k}{\sum_{k=1}^k \#TP_k + \sum_{k=1}^k \#FP_k}
#' }
#'
#' @family classification
#' @export
fdr <- function(actual, predicted, aggregate = FALSE) {
    .Call(`_SLmetrics_fdr`, actual, predicted, aggregate)
}

#' Compute the  \eqn{\text{false}} \eqn{\text{exclusion}} \eqn{\text{rate}}
#'
#' @description
#' The [fer()]-function computes the [false omission rate](https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values#False_omission_rate) (FOR), the proportion of false negatives among the predicted negatives, between
#' two vectors of predicted and observed [factor()] values.
#'
#' When `aggregate = TRUE`, the function returns the micro-average FOR across all classes \eqn{k}. By default, it returns the class-wise FOR.
#'
#' @example man/examples/scr_for.R
#'
#' @usage
#' # false exclusion rate
#' fer(
#'   actual,
#'   predicted,
#'   aggregate = FALSE
#' )
#'
#' @inherit specificity
#'
#' @section Calculation:
#'
#' The metric is calculated for each class \eqn{k} as follows,
#'
#' \deqn{
#'   \frac{\#FN_k}{\#FN_k + \#TN_k}
#' }
#'
#' Where \eqn{\#FN_k} and \eqn{\#TN_k} are the number of false negatives and true negatives, respectively, for each class \eqn{k}.
#'
#' When `aggregate = TRUE`, the `micro`-average is calculated,
#'
#' \deqn{
#'   \frac{\sum_{k=1}^k \#FN_k}{\sum_{k=1}^k \#FN_k + \sum_{k=1}^k \#TN_k}
#' }
#'
#' @family classification
#' @export
fer <- function(actual, predicted, aggregate = FALSE) {
    .Call(`_SLmetrics_fer`, actual, predicted, aggregate)
}

#' Compute the \eqn{\text{false}} \eqn{\text{positive}} \eqn{\text{rate}}
#'
#' @description
#' The [fpr()]-function computes the [False Positive Rate](https://en.wikipedia.org/wiki/False_positive_rate) (FPR), also known as the fall-out ([fallout()]), between
#' two vectors of predicted and observed [factor()] values.
#'
#' When `aggregate = TRUE`, the function returns the micro-average FPR across all classes \eqn{k}.
#' By default, it returns the class-wise FPR.
#'
#' @usage
#' # using`fpr()`
#' fpr(
#'   actual,
#'   predicted,
#'   aggregate = FALSE
#' )
#'
#' @inherit specificity
#'
#' @example man/examples/scr_fpr.R
#'
#' @section Calculation:
#'
#' The metric is calculated for each class \eqn{k} as follows,
#'
#' \deqn{
#'   \frac{\#FP_k}{\#FP_k + \#TN_k}
#' }
#'
#' Where \eqn{\#FP_k} and \eqn{\#TN_k} represent the number of false positives and true negatives, respectively, for each class \eqn{k}.
#'
#' When `aggregate = TRUE`, the micro-average is calculated across all classes,
#'
#' \deqn{
#'   \frac{\sum_{k=1}^k \#FP_k}{\sum_{k=1}^k \#FP_k + \sum_{k=1}^k \#TN_k}
#' }
#'
#' The FPR is the complement of specificity, such that \eqn{\text{FPR} = 1 - \text{Specificity}}.
#'
#' @family classification
#'
#' @export
fpr <- function(actual, predicted, aggregate = FALSE) {
    .Call(`_SLmetrics_fpr`, actual, predicted, aggregate)
}

#' @rdname fpr
#' @usage
#' # using `fallout()`
#' fallout(
#'   actual,
#'   predicted,
#'   aggregate = FALSE
#' )
#' @export
fallout <- function(actual, predicted, aggregate = FALSE) {
    .Call(`_SLmetrics_fallout`, actual, predicted, aggregate)
}

#' Compute the \eqn{\text{Jaccard}} \eqn{\text{index}}
#'
#' @description
#' The [jaccard()]-function computes the [Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index), also known as the Intersection over Union, between
#' two vectors of predicted and observed [factor()] values.
#'
#' When `aggregate = TRUE`, the function returns the micro-average Jaccard Index across all classes \eqn{k}.
#' By default, it returns the class-wise Jaccard Index.
#'
#' @usage
#' # using `jaccard()`-function
#' jaccard(
#'   actual,
#'   predicted,
#'   aggregate = FALSE
#' )
#'
#' @inherit specificity
#'
#' @section Calculation:
#'
#' The metric is calcualted for each class \eqn{k} as follows,
#'
#' \deqn{
#'   \frac{\#TP_k}{\#TP_k + \#FP_k + \#FN_k}
#' }
#'
#' Where \eqn{\#TP_k}, \eqn{\#FP_k}, and \eqn{\#FN_k} represent the number of true positives, false positives, and false negatives for each class \eqn{k}, respectively.
#'
#' When `aggregate = TRUE`, the micro-average is calculated as,
#'
#' \deqn{
#'   \frac{\sum_{i = 1}^{k} TP_i}{\sum_{i = 1}^{k} TP_i + \sum_{i = 1}^{k} FP_k + \sum_{i = 1}^{k} FN_k}
#' }
#'
#' @example man/examples/scr_jaccard.R
#'
#' @family classification
#'
#' @export
jaccard <- function(actual, predicted, aggregate = FALSE) {
    .Call(`_SLmetrics_jaccard`, actual, predicted, aggregate)
}

#' @rdname jaccard
#'
#' @usage
#' # using `csi()`-function
#' csi(
#'   actual,
#'   predicted,
#'   aggregate = FALSE
#' )
#' @export
csi <- function(actual, predicted, aggregate = FALSE) {
    .Call(`_SLmetrics_csi`, actual, predicted, aggregate)
}

#' @rdname jaccard
#'
#' @usage
#' # using `tscore()`-function
#' tscore(
#'   actual,
#'   predicted,
#'   aggregate = FALSE
#' )
#' @export
tscore <- function(actual, predicted, aggregate = FALSE) {
    .Call(`_SLmetrics_tscore`, actual, predicted, aggregate)
}

#' Compute Cohen's \eqn{\kappa}-statistic
#'
#' @description
#' The [kappa()]-function computes [Cohen's \eqn{\kappa}](https://en.wikipedia.org/wiki/Cohen%27s_kappa), a statistic that measures inter-rater agreement for categorical items between
#' two vectors of predicted and observed [factor()] values.
#'
#' If \eqn{\beta \neq 0} the off-diagonals of the confusion matrix are penalized with a factor of
#' \eqn{(y_{+} - y_{i,-})^\beta}. See below for further details.
#'
#' @usage
#' kappa(
#'   actual,
#'   predicted,
#'   beta = 0
#' )
#'
#' @example man/examples/scr_kappa.R
#'
#' @inherit specificity
#'
#' @inheritParams specificity
#' @param beta A <[numeric]> value of [length] 1. 0 by default. If set to a value different from zero, the off-diagonal confusion matrix will be penalized.
#'
#'
#' @section Calculation
#'
#'
#'
#' @family classification
#' @export
kappa <- function(actual, predicted, beta = 0) {
    .Call(`_SLmetrics_kappa`, actual, predicted, beta)
}

#' Compute the \eqn{\text{positive}} \eqn{\text{likelihood}} \eqn{\text{ratio}}
#'
#' @description
#' The [plr()]-function computes the [positive likelihood ratio](https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing), also known as the likelihood ratio for positive results, between
#' two vectors of predicted and observed [factor()] values.
#'
#' When `aggregate = TRUE`, the function returns the micro-average PLR across all classes \eqn{k}.
#' By default, it returns the class-wise PLR.
#'
#' @usage
#' plr(
#'   actual,
#'   predicted,
#'   aggregate = FALSE
#' )
#'
#' @example man/examples/scr_plr_nlr.R
#'
#' @inherit specificity
#'
#' @section Calculation:
#'
#' The metric is calculated for each class \eqn{k} as follows,
#'
#' \deqn{
#'   \frac{\text{Sensitivity}_k}{1 - \text{Specificity}_k}
#' }
#'
#' Where sensitivity (or true positive rate) is calculated as \eqn{\frac{\#TP_k}{\#TP_k + \#FN_k}} and specificity (or true negative rate) is calculated as \eqn{\frac{\#TN_k}{\#TN_k + \#FP_k}}.
#'
#' When `aggregate = TRUE`, the `micro`-average is calculated,
#'
#' \deqn{
#'   \frac{\sum_{k=1}^k \text{Sensitivity}_k}{1 - \sum_{k=1}^k \text{Specificity}_k}
#' }
#'
#' @seealso
#'
#' The [nlr()]-function for the Negative Likehood Ratio (LR-)
#'
#' @family classification
#' @export
plr <- function(actual, predicted, aggregate = FALSE) {
    .Call(`_SLmetrics_plr`, actual, predicted, aggregate)
}

#' Compute the \eqn{\text{negative}} \eqn{\text{likelihood}} \eqn{\text{ratio}}
#'
#' @description
#' The [nlr()]-function computes the [negative likelihood ratio](https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing), also known as the likelihood ratio for negative results, between
#' two vectors of predicted and observed [factor()] values.
#'
#' When `aggregate = TRUE`, the function returns the micro-average NLR across all classes \eqn{k}.
#' By default, it returns the class-wise NLR.
#'
#' @usage
#' nlr(
#'   actual,
#'   predicted,
#'   aggregate = FALSE
#' )
#'
#' @example man/examples/scr_plr_nlr.R
#'
#' @inherit specificity
#'
#' @section Calculation:
#'
#' The metric is calculated for each class \eqn{k} as follows,
#'
#' \deqn{
#'   \frac{1 - \text{Sensitivity}_k}{\text{Specificity}_k}
#' }
#'
#' Where sensitivity (or true positive rate) is calculated as \eqn{\frac{\#TP_k}{\#TP_k + \#FN_k}} and specificity (or true negative rate) is calculated as \eqn{\frac{\#TN_k}{\#TN_k + \#FP_k}}.
#'
#' When `aggregate = TRUE`, the `micro`-average is calculated,
#'
#' \deqn{
#'   \frac{\sum_{k=1}^k (1 - \text{Sensitivity}_k)}{\sum_{k=1}^k \text{Specificity}_k}
#' }
#'
#' @seealso
#'
#' The [plr()]-function for the Positive Likehood Ratio (LR+)
#' @family classification
#' @export
nlr <- function(actual, predicted, aggregate = FALSE) {
    .Call(`_SLmetrics_nlr`, actual, predicted, aggregate)
}

#' Compute the \eqn{\text{Matthews}} \eqn{\text{Correlation}} \eqn{\text{Coefficient}}
#'
#' @description
#' The [mcc()]-function computes the [Matthews Correlation Coefficient](https://en.wikipedia.org/wiki/Matthews_correlation_coefficient) (MCC), also known as the \eqn{\phi}-coefficient, between
#' two vectors of predicted and observed [factor()] values.
#'
#' @usage
#' # 1) `mcc()`-function
#' mcc(
#'   actual,
#'   predicted
#' )
#'
#' @example man/examples/scr_mcc.R
#'
#' @inherit precision
#'
#' @section Calculation:
#'
#' The metric is calculated as follows,
#'
#' \deqn{
#'   \frac{\#TP \times \#TN - \#FP \times \#FN}{\sqrt{(\#TP + \#FP)(\#TP + \#FN)(\#TN + \#FP)(\#TN + \#FN)}}
#' }
#'
#'
#' @returns
#' A named <[numeric]> vector of length k
#'
#' @family classification
#'
#' @export
mcc <- function(actual, predicted) {
    .Call(`_SLmetrics_mcc`, actual, predicted)
}

#' @rdname mcc
#'
#' @usage
#' # 2) `phi()`-function
#' phi(
#'   actual,
#'   predicted
#' )
#'
#' @export
phi <- function(actual, predicted) {
    .Call(`_SLmetrics_phi`, actual, predicted)
}

#' Compute the \eqn{\text{negative}} \eqn{\text{predictive}} \eqn{\text{value}}
#'
#' @description
#' The [npv()]-function computes the [negative predictive value](https://en.wikipedia.org/wiki/Positive_and_negative_predictive_values), also known as the True Negative Predictive Value, between
#' two vectors of predicted and observed [factor()] values.
#'
#' When `aggregate = TRUE`, the function returns the micro-average NPV across all classes \eqn{k}. By default, it returns the class-wise NPV.
#'
#' @usage
#' # `npv()`-function
#' npv(
#'   actual,
#'   predicted,
#'   aggregate = FALSE
#' )
#'
#' @inherit specificity
#'
#' @example man/examples/scr_npv.R
#'
#' @section Calculation:
#'
#' The metric is calculated for each class \eqn{k} as follows,
#'
#' \deqn{
#'   \frac{\#TN_k}{\#TN_k + \#FN_k}
#' }
#'
#' Where \eqn{\#TN_k} and \eqn{\#FN_k} are the number of true negatives and false negatives, respectively, for each class \eqn{k}.
#'
#' When `aggregate = TRUE`, the `micro`-average is calculated,
#'
#' \deqn{
#'   \frac{\sum_{k=1}^k \#TN_k}{\sum_{k=1}^k \#TN_k + \sum_{k=1}^k \#FN_k}
#' }
#'
#' @family classification
#'
#' @export
npv <- function(actual, predicted, aggregate = FALSE) {
    .Call(`_SLmetrics_npv`, actual, predicted, aggregate)
}

#' @rdname precision
#' @method precision factor
#'
#' @export
precision.factor <- function(actual, predicted, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_precision`, actual, predicted, micro, na_rm = na.rm)
}

#' @rdname precision
#' @method precision cmatrix
#'
#' @export
precision.cmatrix <- function(x, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_precision_cmatrix`, x, micro, na_rm = na.rm)
}

#' @rdname precision
#' @method ppv factor
#'
#' @export
ppv.factor <- function(actual, predicted, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_ppv`, actual, predicted, micro, na_rm = na.rm)
}

#' @rdname precision
#' @method ppv cmatrix
#'
#' @export
ppv.cmatrix <- function(x, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_ppv_cmatrix`, x, micro, na_rm = na.rm)
}

#' @rdname recall
#' @method recall factor
#'
#' @export
recall.factor <- function(actual, predicted, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_recall`, actual, predicted, micro, na_rm = na.rm)
}

#' @rdname recall
#'
#' @method recall cmatrix
#' @export
recall.cmatrix <- function(x, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_recall_cmatrix`, x, micro, na_rm = na.rm)
}

#' @rdname recall
#' @method sensitivity factor
#'
#' @export
sensitivity.factor <- function(actual, predicted, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_sensitivity`, actual, predicted, micro, na_rm = na.rm)
}

#' @rdname recall
#'
#' @method sensitivity cmatrix
#' @export
sensitivity.cmatrix <- function(x, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_sensitivity_cmatrix`, x, micro, na_rm = na.rm)
}

#' @rdname recall
#'
#' @method tpr factor
#' @export
tpr.factor <- function(actual, predicted, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_tpr`, actual, predicted, micro, na_rm = na.rm)
}

#' @rdname recall
#'
#' @method tpr cmatrix
#' @export
tpr.cmatrix <- function(x, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_tpr_cmatrix`, x, micro, na_rm = na.rm)
}

#' @rdname specificity
#' @method specificity factor
#'
#' @export
specificity.factor <- function(actual, predicted, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_specificity`, actual, predicted, micro, na_rm = na.rm)
}

#' @rdname specificity
#' @method specificity cmatrix
#'
#' @export
specificity.cmatrix <- function(x, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_specificity_cmatrix`, x, micro, na_rm = na.rm)
}

#' @rdname specificity
#' @method tnr factor
#'
#' @export
tnr.factor <- function(actual, predicted, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_tnr`, actual, predicted, micro, na_rm = na.rm)
}

#' @rdname specificity
#' @method tnr cmatrix
#'
#' @export
tnr.cmatrix <- function(x, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_tnr_cmatrix`, x, micro, na_rm = na.rm)
}

#' @rdname specificity
#' @method selectivity factor
#'
#' @export
selectivity.factor <- function(actual, predicted, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_selectivity`, actual, predicted, micro, na_rm = na.rm)
}

#' @rdname specificity
#' @method selectivity cmatrix
#'
#' @export
selectivity.cmatrix <- function(x, micro = NULL, na.rm = TRUE, ...) {
    .Call(`_SLmetrics_selectivity_cmatrix`, x, micro, na_rm = na.rm)
}

#' Zero-One Loss
#'
#' @description
#' The [zerooneloss()]-function computes the [Zero-One Loss](https://en.wikipedia.org/wiki/Loss_functions_for_classification), a classification loss function that calculates the proportion of misclassified instances between
#' two vectors of predicted and observed [factor()] values.
#'
#' @usage
#' zerooneloss(
#'   actual,
#'   predicted
#' )
#'
#' @inherit specificity
#'
#' @section Calculation:
#'
#' Zero-One Loss is a global metric that measures the proportion of incorrect predictions made by the model. It is calculated as follows,
#'
#' \deqn{
#'   \frac{\#FP + \#FN}{\#TP + \#TN + \#FP + \#FN}
#' }
#'
#' Where \eqn{\#TP}, \eqn{\#TN}, \eqn{\#FP}, and \eqn{\#FN} represent the true positives, true negatives, false positives, and false negatives, respectively.
#'
#' Zero-One Loss provides an overall measure of the model's prediction errors across all classes.
#'
#' @returns
#'
#' A <[numeric]>-vector of [length] 1
#'
#' @example man/examples/scr_zerooneloss.R
#'
#' @family classification
#'
#' @export
zerooneloss <- function(actual, predicted) {
    .Call(`_SLmetrics_zerooneloss`, actual, predicted)
}

#' Compute the \eqn{\text{concordance correlation coefficient}}
#'
#' @description
#' The [ccc()]- and [wccc()]-function computes the simple and weighted [concordance correlation coefficient](https://en.wikipedia.org/wiki/Concordance_correlation_coefficient) between
#' the two vectors of predicted and observed <[numeric]> values.
#'
#' If `correction` is [TRUE] \eqn{\sigma^2} is adjusted by \eqn{\frac{1-n}{n}} in the intermediate steps.
#'
#' @usage
#' # `ccc()`-function
#' ccc(
#'   actual,
#'   predicted,
#'   correction = FALSE
#' )
#'
#' @inherit huberloss
#' @param correction A <[logical]> vector of [length] 1. [FALSE] by default. If [TRUE] the variance and covariance
#' will be adjusted with \eqn{\frac{1-n}{n}}
#'
#' @example man/examples/scr_ccc.R
#'
#' @section Calculation:
#'
#' The metric is calculated as follows,
#'
#' \deqn{
#'   \rho_c = \frac{2 \rho \sigma_x \sigma_y}{\sigma_x^2 + \sigma_y^2 + (\mu_x - \mu_y)^2}
#' }
#'
#' Where \eqn{\rho} is the \eqn{\text{pearson correlation coefficient}}, \eqn{\sigma} is the \eqn{\text{standard deviation}} and \eqn{\mu} is the simple mean of `actual` and `predicted`.
#'
#' If `w` is not [NULL], all calculations are based on the weighted measures.
#'
#' @family regression
#' @export
ccc <- function(actual, predicted, correction = FALSE) {
    .Call(`_SLmetrics_ccc`, actual, predicted, correction)
}

#' @rdname ccc
#'
#' @usage
#' # `wccc()`-function
#' wccc(
#'   actual,
#'   predicted,
#'   w,
#'   correction = FALSE
#' )
#'
#' @export
wccc <- function(actual, predicted, w, correction = FALSE) {
    .Call(`_SLmetrics_wccc`, actual, predicted, w, correction)
}

#' Compute the \eqn{\text{huber loss}}
#'
#' @description
#' The [huberloss()]- and [whuberloss()]-function computes the simple and weighted [huber loss](https://en.wikipedia.org/wiki/Huber_loss) between
#' the predicted and observed <[numeric]> vectors.
#'
#' @usage
#' # `huberloss()`-function
#' huberloss(
#'   actual,
#'   predicted,
#'   delta = 1
#' )
#'
#' @param actual A <[numeric]>-vector of [length] \eqn{n}. The observed (continuous) response variable.
#' @param predicted A <[numeric]>-vector of [length] \eqn{n}. The estimated (continuous) response variable.
#' @param delta A <[numeric]>-vector of [length] 1. 1 by default. The threshold value for switch between functions (see calculation).
#'
#' @section Calculation:
#'
#' The metric is calculated as follows,
#'
#' \deqn{
#'  \frac{1}{2} (y - \upsilon)^2 ~for~ |y - \upsilon| \leq \delta
#' }
#'
#' and
#'
#' \deqn{
#'   \delta |y-\upsilon|-\frac{1}{2} \delta^2 ~for~ \text{otherwise}
#' }
#'
#' where \eqn{y} and \eqn{\upsilon} are the `actual` and `predicted` values respectively. If `w` is not [NULL], then all values
#' are aggregated using the weights.
#'
#'
#' @example man/examples/scr_huberloss.R
#'
#'
#' @family regression
#'
#' @returns A <[numeric]> vector of [length] 1.
#'
#' @export
huberloss <- function(actual, predicted, delta = 1) {
    .Call(`_SLmetrics_huberloss`, actual, predicted, delta)
}

#' @rdname huberloss
#' @usage
#' # `whuberloss()`-function
#' whuberloss(
#'   actual,
#'   predicted,
#'   w,
#'   delta = 1
#' )
#'
#' @param w A <[numeric]>-vector of [length] \eqn{n}. The weight assigned to each observation in the data. See [stats::weighted.mean()] for more details.
#'
#' @export
whuberloss <- function(actual, predicted, w, delta = 1) {
    .Call(`_SLmetrics_whuberloss`, actual, predicted, w, delta)
}

#' Compute the \eqn{\text{mean absolute error}}
#'
#' The [mae()]- and [wmae()]-function computes the simple and weighted [mean absolute error](https://en.wikipedia.org/wiki/Mean_absolute_error) between
#' the observed and predicted <[numeric]> vectors. If `w` is not [NULL] the function returns the weighted mean absolute error.
#'
#' @usage
#' # `mae()`-function
#' mae(
#'   actual,
#'   predicted
#' )
#'
#' @inherit huberloss
#'
#' @example man/examples/scr_mae.R
#'
#' @section Calculation:
#'
#' The metric is calulated as follows,
#'
#' \deqn{
#'   \frac{\sum_i^n |y_i - \upsilon_i|}{n}
#' }
#'
#' If \eqn{w} is not [NULL] the function returns the weigthed version.
#'
#' @family regression
#'
#' @export
mae <- function(actual, predicted) {
    .Call(`_SLmetrics_mae`, actual, predicted)
}

#' @rdname mae
#'
#' @usage
#' # `wmae()`-function
#' wmae(
#'   actual,
#'   predicted,
#'   w
#' )
#' @export
wmae <- function(actual, predicted, w) {
    .Call(`_SLmetrics_wmae`, actual, predicted, w)
}

#' Compute the \eqn{\text{mean absolute percentage error}}
#'
#' The [mape()]- and [wmape()]-function computes the simple and weighted [mean absolute percentage error](https://en.wikipedia.org/wiki/Mean_absolute_percentage_error) between
#' the observed and predicted <[numeric]> vectors. If `w` is not [NULL] the function returns the weighted mean absolute error.
#' @usage
#' # `mape()`-function
#' mape(
#'   actual,
#'   predicted
#' )
#'
#' @inherit huberloss
#'
#' @example man/examples/scr_mape.R
#'
#' @section Calculation:
#'
#' The metric is calculated as,
#'
#' \deqn{
#'   \frac{1}{n} \sum_i^n \frac{|y_i - \upsilon_i|}{|y_i|}
#' }
#'
#' If \eqn{\text{w}} is not [NULL], the weighted version is calculated.
#'
#' @family regression
#' @export
mape <- function(actual, predicted) {
    .Call(`_SLmetrics_mape`, actual, predicted)
}

#' @rdname mape
#'
#' @usage
#' # `wmape()`-function
#' wmape(
#'   actual,
#'   predicted,
#'   w
#' )
#'
#' @export
wmape <- function(actual, predicted, w) {
    .Call(`_SLmetrics_wmape`, actual, predicted, w)
}

#' Compute the \eqn{\text{mean percentage error}}
#'
#' The [mpe()]-function computes the [mean percentage error](https://en.wikipedia.org/wiki/Mean_percentage_error) between
#' the observed and predicted <[numeric]> vectors. If `w` is not [NULL], the function returns the weighted mean percentage error.
#' @usage
#' # `mpe()`-function
#' mpe(
#'   actual,
#'   predicted
#' )
#'
#' @inherit huberloss
#'
#' @example man/examples/scr_mpe.R
#'
#' @section Calculation:
#'
#' The metric is calculated as,
#'
#' \deqn{
#'   \frac{1}{n} \sum_i^n \frac{y_i - \upsilon_i}{y_i}
#' }
#'
#' Where \eqn{y_i} and \eqn{\upsilon_i} are the `actual` and `predicted` values respectively. If \eqn{\text{w}} is not [NULL], the weighted version is calculated.
#'
#' @family regression
#' @export
mpe <- function(actual, predicted) {
    .Call(`_SLmetrics_mpe`, actual, predicted)
}

#' @rdname mpe
#'
#' @usage
#' # `wmpe()`-function
#' wmpe(
#'   actual,
#'   predicted,
#'   w
#' )
#' @export
wmpe <- function(actual, predicted, w) {
    .Call(`_SLmetrics_wmpe`, actual, predicted, w)
}

#' Compute the \eqn{\text{mean squared error}}
#'
#' The [mse()]- and [wmse()]-function computes the simple and weighted [mean squared error](https://en.wikipedia.org/wiki/Mean_squared_error) between
#' the observed and predicted <[numeric]> vectors. If `w` is not [NULL], the function returns the weighted mean squared error.
#' @usage
#' # `mse()`-function
#' mse(
#'   actual,
#'   predicted
#' )
#'
#' @inherit huberloss
#'
#' @example man/examples/scr_mse.R
#'
#' @section Calculation:
#'
#' The metric is calculated as,
#'
#' \deqn{
#'   \frac{1}{n} \sum_i^n (y_i - \upsilon_i)^2
#' }
#'
#' Where \eqn{y_i} and \eqn{\upsilon_i} are the `actual` and `predicted` values respectively. If \eqn{\text{w}} is not [NULL], the weighted version is calculated.
#'
#' @family regression
#' @export
mse <- function(actual, predicted) {
    .Call(`_SLmetrics_mse`, actual, predicted)
}

#' @rdname mse
#'
#' @usage
#' # `wmse()`-function
#' wmse(
#'   actual,
#'   predicted,
#'   w
#' )
#' @export
wmse <- function(actual, predicted, w) {
    .Call(`_SLmetrics_wmse`, actual, predicted, w)
}

#' Compute the \eqn{\text{root mean squared error}}
#'
#' The [rmse()]- and [wrmse()]-function computes the simple and weighted [root mean squared error](https://en.wikipedia.org/wiki/Root-mean-square_deviation) between
#' the observed and predicted <[numeric]> vectors. If `w` is not [NULL], the function returns the weighted root mean squared error.
#' @usage
#' # `rmse()`-function
#' rmse(
#'   actual,
#'   predicted
#' )
#'
#' @inherit huberloss
#'
#' @example man/examples/scr_rmse.R
#'
#' @section Calculation:
#'
#' The metric is calculated as,
#'
#' \deqn{
#'   \sqrt{\frac{1}{n} \sum_i^n (y_i - \upsilon_i)^2}
#' }
#'
#' Where \eqn{y_i} and \eqn{\upsilon_i} are the `actual` and `predicted` values respectively. If \eqn{\text{w}} is not [NULL], the weighted version is calculated.
#'
#' @family regression
#' @export
rmse <- function(actual, predicted) {
    .Call(`_SLmetrics_rmse`, actual, predicted)
}

#' @rdname rmse
#'
#' @usage
#' # `wrmse()`-function
#' wrmse(
#'   actual,
#'   predicted,
#'   w
#' )
#' @export
wrmse <- function(actual, predicted, w) {
    .Call(`_SLmetrics_wrmse`, actual, predicted, w)
}

#' Compute the \eqn{\text{root mean squared logarithmic error}}
#'
#' The [rmsle()]- and [wrmsle()]-function computes the simple and weighted root mean squared logarithmic error between
#' the observed and predicted <[numeric]> vectors. If `w` is not [NULL], the function returns the weighted root mean squared logarithmic error.
#' @usage
#' # `rmsle()`-function
#' rmsle(
#'   actual,
#'   predicted
#' )
#'
#' @inherit huberloss
#'
#' @example man/examples/scr_rmsle.R
#'
#' @section Calculation:
#'
#' The metric is calculated as,
#'
#' \deqn{
#'   \sqrt{\frac{1}{n} \sum_i^n (\log(1 + y_i) - \log(1 + \upsilon_i))^2}
#' }
#'
#' Where \eqn{y_i} and \eqn{\upsilon_i} are the `actual` and `predicted` values respectively. If \eqn{\text{w}} is not [NULL], the weighted version is calculated.
#'
#' @family regression
#' @export
rmsle <- function(actual, predicted) {
    .Call(`_SLmetrics_rmsle`, actual, predicted)
}

#' @rdname rmsle
#'
#' @usage
#' # `wrmsle()`-function
#' wrmsle(
#'   actual,
#'   predicted,
#'   w
#' )
#'
#' @export
wrmsle <- function(actual, predicted, w) {
    .Call(`_SLmetrics_wrmsle`, actual, predicted, w)
}

#' Compute the \eqn{R^2}
#'
#' @description
#' The [rsq()]-function calculates the \eqn{R^2}, the [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination), between the ovserved
#' and predicted <[numeric]> vectors. By default [rsq()] returns the unadjusted \eqn{R^2}. For adjusted \eqn{R^2} set \eqn{k = \kappa - 1}, where \eqn{\kappa} is the number of parameters.
#'
#' @usage
#' # `rsq()`-function
#' rsq(
#'   actual,
#'   predicted,
#'   k = 0
#' )
#'
#' @inherit huberloss
#' @param k A <[numeric]>-vector of [length] 1. 0 by default. If \eqn{k>0}
#' the function returns the adjusted \eqn{R^2}.
#'
#' @section Calculation:
#'
#' The metric is calculated as follows,
#'
#' \deqn{
#'   R^2 = 1 - \frac{\text{SSE}}{\text{SST}} \frac{n-1}{n - (k + 1)}
#' }
#'
#' Where \eqn{\text{SSE}} is the sum of squared errors, \eqn{\text{SST}} is total sum of squared errors, \eqn{n} is the number of observations, and \eqn{k} is the number of non-constant parameters.
#'
#' @family regression
#'
rsq <- function(actual, predicted, k = 0) {
    .Call(`_SLmetrics_rsq`, actual, predicted, k)
}

#' Compute the \eqn{\text{symmetric mean absolute percentage error}}
#'
#' The [smape()]- and [wsmape()]-function computes the simple and weighted [symmetric mean absolute percentage error](https://en.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error).
#'
#' @usage
#' # `smape()`-function
#' smape(
#'   actual,
#'   predicted
#' )
#'
#' @inherit huberloss
#'
#' @example man/examples/scr_smape.R
#'
#' @section Calculation:
#'
#' The metric is calculated as follows,
#'
#' \deqn{
#'   \sum_i^n \frac{1}{n} \frac{|y_i - \upsilon_i|}{\frac{|y_i|+|\upsilon_i|}{2}}
#' }
#'
#' where \eqn{y_i} and \eqn{\upsilon_i} is the `actual` and `predicted` values respectively. If `w` is not [NULL], the metric is calculated
#' using weights.
#'
#' @family regression
#' @export
smape <- function(actual, predicted) {
    .Call(`_SLmetrics_smape`, actual, predicted)
}

#' @rdname smape
#'
#' @usage
#' # `wsmape()`-function
#' wsmape(
#'   actual,
#'   predicted,
#'   w
#' )
#'
#' @export
wsmape <- function(actual, predicted, w) {
    .Call(`_SLmetrics_wsmape`, actual, predicted, w)
}

